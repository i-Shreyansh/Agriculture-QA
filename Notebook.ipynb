{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9944743,"sourceType":"datasetVersion","datasetId":6114985}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-20T06:24:05.612130Z","iopub.execute_input":"2024-11-20T06:24:05.612389Z","iopub.status.idle":"2024-11-20T06:24:06.682349Z","shell.execute_reply.started":"2024-11-20T06:24:05.612363Z","shell.execute_reply":"2024-11-20T06:24:06.681427Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# System Configs","metadata":{}},{"cell_type":"code","source":"!nvidia-smi\n","metadata":{"execution":{"iopub.status.busy":"2024-11-19T11:14:49.730200Z","iopub.execute_input":"2024-11-19T11:14:49.730566Z","iopub.status.idle":"2024-11-19T11:14:50.848050Z","shell.execute_reply.started":"2024-11-19T11:14:49.730523Z","shell.execute_reply":"2024-11-19T11:14:50.847209Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import tensorflow as tf\n\n# Check if GPU is available\n  # Check if TensorFlow detects a GPU\n    print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n    print(\"GPU Devices:\", tf.config.list_physical_devices('GPU'))\nelse:\n    print(\"No GPU found.\")\n    gpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    print(f\"GPUs available: {[gpu.name for gpu in gpus]}\")\n  \n    \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch==2.5.1+cu121 torchvision==0.20.1+cu121 torchaudio==2.5.1+cu121 --index-url https://download.pytorch.org/whl/cu121\n","metadata":{"execution":{"iopub.status.busy":"2024-11-19T18:15:26.839341Z","iopub.status.idle":"2024-11-19T18:15:26.839773Z","shell.execute_reply.started":"2024-11-19T18:15:26.839536Z","shell.execute_reply":"2024-11-19T18:15:26.839558Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nprint(torch.__version__)  # PyTorch version\nprint(torch.version.cuda)  # CUDA version used by PyTorch\nprint(torch.cuda.is_available())  # Check if GPU is accessible\n","metadata":{"execution":{"iopub.status.busy":"2024-11-19T11:22:17.349192Z","iopub.execute_input":"2024-11-19T11:22:17.349900Z","iopub.status.idle":"2024-11-19T11:22:17.355132Z","shell.execute_reply.started":"2024-11-19T11:22:17.349866Z","shell.execute_reply":"2024-11-19T11:22:17.354043Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%capture\n# !pip install unsloth\n# Also get the latest nightly Unsloth!\n\n    \n!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n!pip install bitsandbytes triton unsloth-zoo xformers ","metadata":{"execution":{"iopub.status.busy":"2024-11-19T11:25:27.437196Z","iopub.execute_input":"2024-11-19T11:25:27.437590Z","iopub.status.idle":"2024-11-19T11:25:49.619271Z","shell.execute_reply.started":"2024-11-19T11:25:27.437553Z","shell.execute_reply":"2024-11-19T11:25:49.618216Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python --version\n!pip show torch | grep Version\n!python -m torch.utils.collect_env\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T15:47:43.033193Z","iopub.execute_input":"2024-11-20T15:47:43.033597Z","iopub.status.idle":"2024-11-20T15:48:24.534121Z","shell.execute_reply.started":"2024-11-20T15:47:43.033562Z","shell.execute_reply":"2024-11-20T15:48:24.532408Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Python 3.10.14\nVersion: 2.4.0+cpu\n/opt/conda/lib/python3.10/runpy.py:126: RuntimeWarning: 'torch.utils.collect_env' found in sys.modules after import of package 'torch.utils', but prior to execution of 'torch.utils.collect_env'; this may result in unpredictable behaviour\n  warn(RuntimeWarning(msg))\nCollecting environment information...\nPyTorch version: 2.4.0+cpu\nIs debug build: False\nCUDA used to build PyTorch: None\nROCM used to build PyTorch: N/A\n\nOS: Ubuntu 20.04.6 LTS (x86_64)\nGCC version: (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\nClang version: Could not collect\nCMake version: version 3.16.3\nLibc version: glibc-2.31\n\nPython version: 3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0] (64-bit runtime)\nPython platform: Linux-6.6.56+-x86_64-with-glibc2.31\nIs CUDA available: False\nCUDA runtime version: No CUDA\nCUDA_MODULE_LOADING set to: N/A\nGPU models and configuration: No CUDA\nNvidia driver version: No CUDA\ncuDNN version: No CUDA\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nArchitecture:                         x86_64\nCPU op-mode(s):                       32-bit, 64-bit\nByte Order:                           Little Endian\nAddress sizes:                        46 bits physical, 48 bits virtual\nCPU(s):                               4\nOn-line CPU(s) list:                  0-3\nThread(s) per core:                   2\nCore(s) per socket:                   2\nSocket(s):                            1\nNUMA node(s):                         1\nVendor ID:                            GenuineIntel\nCPU family:                           6\nModel:                                79\nModel name:                           Intel(R) Xeon(R) CPU @ 2.20GHz\nStepping:                             0\nCPU MHz:                              2199.998\nBogoMIPS:                             4399.99\nHypervisor vendor:                    KVM\nVirtualization type:                  full\nL1d cache:                            64 KiB\nL1i cache:                            64 KiB\nL2 cache:                             512 KiB\nL3 cache:                             55 MiB\nNUMA node0 CPU(s):                    0-3\nVulnerability Gather data sampling:   Not affected\nVulnerability Itlb multihit:          Not affected\nVulnerability L1tf:                   Mitigation; PTE Inversion\nVulnerability Mds:                    Mitigation; Clear CPU buffers; SMT Host state unknown\nVulnerability Meltdown:               Mitigation; PTI\nVulnerability Mmio stale data:        Vulnerable: Clear CPU buffers attempted, no microcode; SMT Host state unknown\nVulnerability Reg file data sampling: Not affected\nVulnerability Retbleed:               Mitigation; IBRS\nVulnerability Spec rstack overflow:   Not affected\nVulnerability Spec store bypass:      Mitigation; Speculative Store Bypass disabled via prctl\nVulnerability Spectre v1:             Mitigation; usercopy/swapgs barriers and __user pointer sanitization\nVulnerability Spectre v2:             Mitigation; IBRS; IBPB conditional; STIBP conditional; RSB filling; PBRSB-eIBRS Not affected; BHI SW loop, KVM SW loop\nVulnerability Srbds:                  Not affected\nVulnerability Tsx async abort:        Mitigation; Clear CPU buffers; SMT Host state unknown\nFlags:                                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n\nVersions of relevant libraries:\n[pip3] flake8==7.1.1\n[pip3] mypy-extensions==1.0.0\n[pip3] numpy==1.26.4\n[pip3] onnx==1.17.0\n[pip3] optree==0.11.0\n[pip3] pytorch-ignite==0.5.1\n[pip3] pytorch-lightning==2.4.0\n[pip3] torch==2.4.0+cpu\n[pip3] torchaudio==2.4.0+cpu\n[pip3] torchinfo==1.8.0\n[pip3] torchmetrics==1.4.2\n[pip3] torchvision==0.19.0+cpu\n[conda] mkl                       2024.2.2            ha957f24_15    conda-forge\n[conda] numpy                     1.26.4          py310hb13e2d6_0    conda-forge\n[conda] optree                    0.11.0                   pypi_0    pypi\n[conda] pytorch-ignite            0.5.1                    pypi_0    pypi\n[conda] pytorch-lightning         2.4.0                    pypi_0    pypi\n[conda] torch                     2.4.0+cpu                pypi_0    pypi\n[conda] torchaudio                2.4.0+cpu                pypi_0    pypi\n[conda] torchinfo                 1.8.0                    pypi_0    pypi\n[conda] torchmetrics              1.4.2                    pypi_0    pypi\n[conda] torchvision               0.19.0+cpu               pypi_0    pypi\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"\nimport json\nimport pandas as pd\nimport wandb\nfrom unsloth import FastLanguageModel","metadata":{"execution":{"iopub.status.busy":"2024-11-21T14:24:16.690861Z","iopub.execute_input":"2024-11-21T14:24:16.691689Z","iopub.status.idle":"2024-11-21T14:24:16.695961Z","shell.execute_reply.started":"2024-11-21T14:24:16.691652Z","shell.execute_reply":"2024-11-21T14:24:16.695105Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Data Imports","metadata":{}},{"cell_type":"code","source":"df1 = pd.read_parquet('/kaggle/input/agriculture-qa/train-00000-of-00001.parquet')\ndf2 = pd.read_json(\"/kaggle/input/agriculture-qa/agricult_data.json\")","metadata":{"execution":{"iopub.status.busy":"2024-11-21T14:56:51.025622Z","iopub.execute_input":"2024-11-21T14:56:51.026062Z","iopub.status.idle":"2024-11-21T14:56:51.753264Z","shell.execute_reply.started":"2024-11-21T14:56:51.026027Z","shell.execute_reply":"2024-11-21T14:56:51.752455Z"},"trusted":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":"df2 = df2.drop(columns=['instruction'])\ndf2.columns = df1.columns\ndf = pd.concat([df1, df2], ignore_index=True)\ndf","metadata":{"execution":{"iopub.status.busy":"2024-11-21T14:56:54.267066Z","iopub.execute_input":"2024-11-21T14:56:54.267988Z","iopub.status.idle":"2024-11-21T14:56:54.306280Z","shell.execute_reply.started":"2024-11-21T14:56:54.267950Z","shell.execute_reply":"2024-11-21T14:56:54.305203Z"},"trusted":true},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"                                                question  \\\n0             why is crop rotation important in farming?   \n1      What farming practice helps prevent soil erosion?   \n2                                  what is crop rotation   \n3          what are the different methods of irrigation?   \n4                              why is soil health vital?   \n...                                                  ...   \n28526  Addressing nitrogen deficiency in a newly esta...   \n28527  Preventing erosion on riverbanks used for cult...   \n28528  Reviving an abandoned vineyard with minimal in...   \n28529     Managing waterlogged fields after heavy rains.   \n28530  Attracting beneficial wildlife to a monocultur...   \n\n                                                 answers  \n0      This helps to prevent soil erosion and depleti...  \n1                                          Crop Rotation  \n2      Crop rotation is the practice of growing a ser...  \n3      surface irrigation, drip irrigation, and sprin...  \n4      Soil health is critical to crop growth and pro...  \n...                                                  ...  \n28526  Intersperse nitrogen-fixing plants among fruit...  \n28527  Plant vetiver grass along the banks for its de...  \n28528  Introduce ground cover crops to improve soil l...  \n28529  Construct raised beds or channels to improve d...  \n28530  Create hedgerows and wildflower strips around ...  \n\n[28531 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>why is crop rotation important in farming?</td>\n      <td>This helps to prevent soil erosion and depleti...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What farming practice helps prevent soil erosion?</td>\n      <td>Crop Rotation</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>what is crop rotation</td>\n      <td>Crop rotation is the practice of growing a ser...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>what are the different methods of irrigation?</td>\n      <td>surface irrigation, drip irrigation, and sprin...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>why is soil health vital?</td>\n      <td>Soil health is critical to crop growth and pro...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>28526</th>\n      <td>Addressing nitrogen deficiency in a newly esta...</td>\n      <td>Intersperse nitrogen-fixing plants among fruit...</td>\n    </tr>\n    <tr>\n      <th>28527</th>\n      <td>Preventing erosion on riverbanks used for cult...</td>\n      <td>Plant vetiver grass along the banks for its de...</td>\n    </tr>\n    <tr>\n      <th>28528</th>\n      <td>Reviving an abandoned vineyard with minimal in...</td>\n      <td>Introduce ground cover crops to improve soil l...</td>\n    </tr>\n    <tr>\n      <th>28529</th>\n      <td>Managing waterlogged fields after heavy rains.</td>\n      <td>Construct raised beds or channels to improve d...</td>\n    </tr>\n    <tr>\n      <th>28530</th>\n      <td>Attracting beneficial wildlife to a monocultur...</td>\n      <td>Create hedgerows and wildflower strips around ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>28531 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":31},{"cell_type":"markdown","source":"# Data Preprocess","metadata":{}},{"cell_type":"code","source":"max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T14:57:03.255823Z","iopub.execute_input":"2024-11-21T14:57:03.256229Z","iopub.status.idle":"2024-11-21T14:57:03.260599Z","shell.execute_reply.started":"2024-11-21T14:57:03.256188Z","shell.execute_reply":"2024-11-21T14:57:03.259659Z"},"trusted":true},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# model, tokenizer = FastLanguageModel.from_pretrained(\n#     model_name = \"unsloth/Meta-Llama-3.1-8B\",\n#     max_seq_length = max_seq_length,\n#     dtype = dtype,\n#     load_in_4bit = load_in_4bit,\n#     # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n# )\n# model.save_pretrained(\"lora_model\") # Local saving\n# tokenizer.save_pretrained(\"lora_model\")","metadata":{"execution":{"iopub.status.busy":"2024-11-20T07:53:03.013576Z","iopub.execute_input":"2024-11-20T07:53:03.014634Z","iopub.status.idle":"2024-11-20T07:53:03.019196Z","shell.execute_reply.started":"2024-11-20T07:53:03.014585Z","shell.execute_reply":"2024-11-20T07:53:03.018212Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-21T14:57:17.913584Z","iopub.execute_input":"2024-11-21T14:57:17.913917Z","iopub.status.idle":"2024-11-21T14:57:31.827525Z","shell.execute_reply.started":"2024-11-21T14:57:17.913888Z","shell.execute_reply":"2024-11-21T14:57:31.826540Z"},"trusted":true},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2024.11.8: Fast Llama patching. Transformers = 4.46.3.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.5.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00cad5f27cd94ad287c3681fe393ad6b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e50d9ad268774d338b659e4eb8f05f8e"}},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"model = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-21T15:20:42.863682Z","iopub.execute_input":"2024-11-21T15:20:42.864088Z","iopub.status.idle":"2024-11-21T15:20:49.660913Z","shell.execute_reply.started":"2024-11-21T15:20:42.864035Z","shell.execute_reply":"2024-11-21T15:20:49.660245Z"},"trusted":true},"outputs":[{"name":"stderr","text":"Unsloth 2024.11.8 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"# alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n\n\n# ### Input:\n# {}\n\n# ### Response:\n# {}\"\"\"\n\n# EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n# def formatting_prompts_func(examples):\n    \n#     inputs       = examples[\"question\"]\n#     outputs      = examples[\"answers\"]\n#     texts = []\n#     for input, output in zip(inputs, outputs):\n#         # Must add EOS_TOKEN, otherwise your generation will go on forever!\n#         text = alpaca_prompt.format(input, output) + EOS_TOKEN\n#         texts.append(text)\n#     return { \"text\" : texts, }\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T08:21:04.681054Z","iopub.execute_input":"2024-11-20T08:21:04.681463Z","iopub.status.idle":"2024-11-20T08:21:04.687257Z","shell.execute_reply.started":"2024-11-20T08:21:04.681429Z","shell.execute_reply":"2024-11-20T08:21:04.686239Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from datasets import Dataset\n\n# Prepare conversations for formatting\nconversations = [\n    [{\"role\": \"user\", \"content\": row[\"question\"]}, {\"role\": \"assistant\", \"content\": row[\"answers\"]}]\n    for _, row in df.iterrows()\n]\n\n# Create a Hugging Face Dataset\nhf_dataset = Dataset.from_dict({\"conversations\": conversations})\nhf_dataset","metadata":{"execution":{"iopub.status.busy":"2024-11-21T14:58:12.449388Z","iopub.execute_input":"2024-11-21T14:58:12.449711Z","iopub.status.idle":"2024-11-21T14:58:13.757341Z","shell.execute_reply.started":"2024-11-21T14:58:12.449685Z","shell.execute_reply":"2024-11-21T14:58:13.756511Z"},"trusted":true},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['conversations'],\n    num_rows: 28531\n})"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"hf_dataset[:2]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T15:17:06.243557Z","iopub.execute_input":"2024-11-21T15:17:06.244395Z","iopub.status.idle":"2024-11-21T15:17:06.249905Z","shell.execute_reply.started":"2024-11-21T15:17:06.244359Z","shell.execute_reply":"2024-11-21T15:17:06.249120Z"}},"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"{'conversations': [[{'content': 'why is crop rotation important in farming?',\n    'role': 'user'},\n   {'content': 'This helps to prevent soil erosion and depletion, and can also help to control pests and diseases',\n    'role': 'assistant'}],\n  [{'content': 'What farming practice helps prevent soil erosion?',\n    'role': 'user'},\n   {'content': 'Crop Rotation', 'role': 'assistant'}]]}"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"from unsloth.chat_templates import get_chat_template\n\ntokenizer = get_chat_template(\n    tokenizer,\n    chat_template = \"llama-3.1\",\n)\n\ndef formatting_prompts_func(examples):\n    convos = examples[\"conversations\"]\n    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n    return { \"text\" : texts, }\n\n\n# Apply the formatting function\nformatted_dataset = hf_dataset.map(formatting_prompts_func, batched=True)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T15:18:44.668097Z","iopub.execute_input":"2024-11-21T15:18:44.668941Z","iopub.status.idle":"2024-11-21T15:18:46.259174Z","shell.execute_reply.started":"2024-11-21T15:18:44.668906Z","shell.execute_reply":"2024-11-21T15:18:46.258292Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/28531 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b93a537547ad4250b5550a4573dbe1b3"}},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"hf_dataset[2]","metadata":{"execution":{"iopub.status.busy":"2024-11-21T15:19:10.484433Z","iopub.execute_input":"2024-11-21T15:19:10.484774Z","iopub.status.idle":"2024-11-21T15:19:10.490968Z","shell.execute_reply.started":"2024-11-21T15:19:10.484743Z","shell.execute_reply":"2024-11-21T15:19:10.489943Z"},"trusted":true},"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"{'conversations': [{'content': 'what is crop rotation', 'role': 'user'},\n  {'content': 'Crop rotation is the practice of growing a series of different crops in the same area over several seasons',\n   'role': 'assistant'}]}"},"metadata":{}}],"execution_count":61},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\ntoken = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T15:02:25.477697Z","iopub.execute_input":"2024-11-21T15:02:25.478611Z","iopub.status.idle":"2024-11-21T15:02:25.714510Z","shell.execute_reply.started":"2024-11-21T15:02:25.478571Z","shell.execute_reply":"2024-11-21T15:02:25.713444Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"hf_dataset.push_to_hub(\"ShuklaShreyansh/Agriculture-QA\",token=token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T15:10:07.208559Z","iopub.execute_input":"2024-11-21T15:10:07.208921Z","iopub.status.idle":"2024-11-21T15:10:08.934792Z","shell.execute_reply.started":"2024-11-21T15:10:07.208880Z","shell.execute_reply":"2024-11-21T15:10:08.933700Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"945bbb405b1a41f48a09be5a3c6e4f1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Creating parquet from Arrow format:   0%|          | 0/29 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d5527599694449f9385e7156318c668"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5634ca99a054e00ae6cb2333f6ab35c"}},"metadata":{}},{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/datasets/ShuklaShreyansh/Agriculture-QA/commit/9c5925307b0bd653f12b80d28c5e9683612be889', commit_message='Upload dataset', commit_description='', oid='9c5925307b0bd653f12b80d28c5e9683612be889', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/ShuklaShreyansh/Agriculture-QA', endpoint='https://huggingface.co', repo_type='dataset', repo_id='ShuklaShreyansh/Agriculture-QA'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"!wandb login\n# !wandb login --relogin","metadata":{"execution":{"iopub.status.busy":"2024-11-20T07:17:23.087083Z","iopub.execute_input":"2024-11-20T07:17:23.087429Z","iopub.status.idle":"2024-11-20T07:17:26.348196Z","shell.execute_reply.started":"2024-11-20T07:17:23.087391Z","shell.execute_reply":"2024-11-20T07:17:26.347025Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"\nimport torch\nfrom trl import SFTTrainer\nfrom transformers import TrainingArguments, DataCollatorForSeq2Seq\nfrom unsloth import is_bfloat16_supported\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = hf_dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    \n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        num_train_epochs = 1, # Set this for 1 full training run.\n#         max_steps = 60,\n        learning_rate = 2e-4,\n        fp16 = not is_bfloat16_supported(),\n        bf16 = is_bfloat16_supported(),\n        logging_steps = 1,\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs\",\n        report_to = \"wandb\", # Use this for WandB etc\n    ),\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-21T15:21:15.515724Z","iopub.execute_input":"2024-11-21T15:21:15.516421Z","iopub.status.idle":"2024-11-21T15:21:22.278997Z","shell.execute_reply.started":"2024-11-21T15:21:15.516386Z","shell.execute_reply":"2024-11-21T15:21:22.278200Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map (num_proc=2):   0%|          | 0/28531 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cef1391190944f7485aa443c3eff6cb7"}},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"from unsloth.chat_templates import train_on_responses_only\ntrainer = train_on_responses_only(\n    trainer,\n    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T08:39:00.424860Z","iopub.execute_input":"2024-11-20T08:39:00.425193Z","iopub.status.idle":"2024-11-20T08:39:02.143445Z","shell.execute_reply.started":"2024-11-20T08:39:00.425165Z","shell.execute_reply":"2024-11-20T08:39:02.142612Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T08:39:18.247105Z","iopub.execute_input":"2024-11-20T08:39:18.247463Z","iopub.status.idle":"2024-11-20T08:39:18.255787Z","shell.execute_reply.started":"2024-11-20T08:39:18.247430Z","shell.execute_reply":"2024-11-20T08:39:18.254923Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\ntokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])","metadata":{"execution":{"iopub.status.busy":"2024-11-20T08:39:48.564378Z","iopub.execute_input":"2024-11-20T08:39:48.564742Z","iopub.status.idle":"2024-11-20T08:39:48.572154Z","shell.execute_reply.started":"2024-11-20T08:39:48.564710Z","shell.execute_reply":"2024-11-20T08:39:48.571438Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-11-20T08:40:56.718272Z","iopub.execute_input":"2024-11-20T08:40:56.718967Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save/Load","metadata":{}},{"cell_type":"code","source":"model.save_pretrained(\"model\") # Local saving\nmodel.save_pretrained_merged(\"model\")\ntokenizer.save_pretrained(\"model\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T14:28:01.531814Z","iopub.execute_input":"2024-11-21T14:28:01.532193Z","iopub.status.idle":"2024-11-21T14:28:38.585744Z","shell.execute_reply.started":"2024-11-21T14:28:01.532122Z","shell.execute_reply":"2024-11-21T14:28:38.583051Z"}},"outputs":[{"name":"stderr","text":"Unsloth: You're not saving a tokenizer as well?\nYou can do it separately via `tokenizer.save_pretrained(...)`\nUnsloth: You have 2 CPUs. Using `safe_serialization` is 10x slower.\nWe shall switch to Pytorch saving, which will take 3 minutes and not 30 minutes.\nTo force `safe_serialization`, set it to `None` instead.\nUnsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\nmodel which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\nUnsloth: Will remove a cached repo with size 2.2G\n","output_type":"stream"},{"name":"stdout","text":"Unsloth: Merging 4bit and LoRA weights to 16bit...\nUnsloth: Will use up to 18.83 out of 31.35 RAM for saving.\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:00<00:00, 255.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nUnsloth: Saving model... This might take 5 minutes for Llama-7b...\nUnsloth: Saving model/pytorch_model-00001-of-00002.bin...\nUnsloth: Saving model/pytorch_model-00002-of-00002.bin...\nDone.\n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"('model/tokenizer_config.json',\n 'model/special_tokens_map.json',\n 'model/tokenizer.json')"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# Now if you want to load the LoRA adapters we just saved for inference, set False to True:\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True\n\n\nfrom unsloth import FastLanguageModel\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"/kaggle/working/fine-tuned Llama-3.2-3B-Instruct\", # YOUR MODEL YOU USED FOR TRAINING\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:05:03.963579Z","iopub.execute_input":"2024-11-20T17:05:03.964004Z","iopub.status.idle":"2024-11-20T17:05:32.950597Z","shell.execute_reply.started":"2024-11-20T17:05:03.963971Z","shell.execute_reply":"2024-11-20T17:05:32.949876Z"},"trusted":true},"outputs":[{"name":"stdout","text":"==((====))==  Unsloth 2024.11.7: Fast Llama patching. Transformers = 4.46.3.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.5.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a24415bea4d4191ac65fc5d3b37aa84"}},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"## Save to HuggingFace_hub","metadata":{}},{"cell_type":"code","source":"# Push model to the hub\ntoken = os.getenv(\"HUGGINGFACE_TOKEN\")\nmodel.push_to_hub(\"ShuklaShreyansh/Agro-QA\", token=token)\nmodel.push_to_hub_merged(\"ShuklaShreyansh/Agro-QA\", token=token)\ntokenizer.push_to_hub(\"ShuklaShreyansh/Agro-QA\", token=token)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:45:44.308541Z","iopub.execute_input":"2024-11-20T17:45:44.308885Z","iopub.status.idle":"2024-11-20T17:47:20.238075Z","shell.execute_reply.started":"2024-11-20T17:45:44.308852Z","shell.execute_reply":"2024-11-20T17:47:20.237378Z"},"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8fae712c7e4f4219ace2f73dea1e14e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f404c7270cb4338ab4e026b7e52e978"}},"metadata":{}},{"name":"stdout","text":"Saved model to https://huggingface.co/ShuklaShreyansh/Agro-QA\nUnsloth: Merging 4bit and LoRA weights to 16bit...\nUnsloth: Will use up to 19.68 out of 31.35 RAM for saving.\n","output_type":"stream"},{"name":"stderr","text":"100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28/28 [00:04<00:00,  6.70it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nUnsloth: Saving model... This might take 5 minutes for Llama-7b...\nUnsloth: Saving /tmp/Agro-QA/pytorch_model-00001-of-00002.bin...\nUnsloth: Saving /tmp/Agro-QA/pytorch_model-00002-of-00002.bin...\n","output_type":"stream"},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"},{"name":"stdout","text":"Done.\nSaved merged model to https://huggingface.co/ShuklaShreyansh/Agro-QA\n","output_type":"stream"},{"name":"stderr","text":"No files have been modified since last commit. Skipping to prevent empty commit.\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"# from unsloth.chat_templates import get_chat_template\n\n# tokenizer = get_chat_template(\n#     tokenizer,\n#     chat_template = \"llama-3.1\",\n# )\n# FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n\n# messages = [\n#     {\"role\": \"user\", \"content\": \"Continue the fibonnaci sequence: 1, 1, 2, 3, 5, 8,\"},\n# ]\n# inputs = tokenizer.apply_chat_template(\n#     messages,\n#     tokenize = True,\n#     add_generation_prompt = True, # Must add for generation\n#     return_tensors = \"pt\",\n# ).to(\"cuda\")\n\n# outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n#                          temperature = 1.5, min_p = 0.1)\n# tokenizer.batch_decode(outputs)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T17:15:59.277789Z","iopub.execute_input":"2024-11-20T17:15:59.278551Z","iopub.status.idle":"2024-11-20T17:15:59.282656Z","shell.execute_reply.started":"2024-11-20T17:15:59.278514Z","shell.execute_reply":"2024-11-20T17:15:59.281686Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n\n# messages = [\n#     {\"role\": \"user\", \"content\": \"What is Agriculture?\"},\n# ]\n# inputs = tokenizer.apply_chat_template(\n#     messages,\n#     tokenize = True,\n#     add_generation_prompt = True, # Must add for generation\n#     return_tensors = \"pt\",\n# ).to(\"cuda\")\n\n# from transformers import TextStreamer\n# text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n# _ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n#                    use_cache = True, temperature = 1.5, min_p = 0.1)","metadata":{"execution":{"iopub.status.busy":"2024-11-21T10:43:44.320302Z","iopub.execute_input":"2024-11-21T10:43:44.320670Z","iopub.status.idle":"2024-11-21T10:43:53.108407Z","shell.execute_reply.started":"2024-11-21T10:43:44.320624Z","shell.execute_reply":"2024-11-21T10:43:53.107717Z"},"trusted":true},"outputs":[{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"Agriculture is the practice of cultivating plants and animals on a farm or other landholdings to produce food, feed, and other products. It involves various activities such as planting, harvesting, and processing crops, as well as raising livestock, managing soil quality, and controlling pests and diseases.\n\nThe primary goal of agriculture is to produce a steady supply of food and other agricultural products to feed and sustain human populations. However, modern agriculture also aims to provide other benefits, including:\n\n1. Environmental sustainability: This includes practices like conservation tillage, crop rotation, and integrated pest management (IPM) to reduce soil erosion, promote biodiversity,\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Inference from HuggingFace","metadata":{}},{"cell_type":"code","source":"from unsloth import FastLanguageModel\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nimport torch\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\ntoken = user_secrets.get_secret(\"HUGGINGFACE_TOKEN\")\nmax_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True\nmodel_name = \"ShuklaShreyansh/Agro-QA\"\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    token = token, # use one if using gated models like meta-llama/Llama-2-7b-hf\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T14:13:26.766662Z","iopub.execute_input":"2024-11-21T14:13:26.767038Z","iopub.status.idle":"2024-11-21T14:14:11.882517Z","shell.execute_reply.started":"2024-11-21T14:13:26.767002Z","shell.execute_reply":"2024-11-21T14:14:11.881584Z"},"trusted":true},"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\nðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n==((====))==  Unsloth 2024.11.8: Fast Llama patching. Transformers = 4.46.3.\n   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\nO^O/ \\_/ \\    Pytorch: 2.5.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\nUnsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"543074fed54445bd8526eca61e1b64cc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be4865943ed54aaca0208a4b9f64078b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/54.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bba953c611a04eca93cea0c084491a35"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"983ba6c540a04826a5900b6986e60054"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e59d1781cc0a4cc9a2fff1deadfb3d2a"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n\nmessages = [\n    {\"role\": \"user\", \"content\": \"What is Agriculture?\"},\n]\ninputs = tokenizer.apply_chat_template(\n    messages,\n    tokenize = True,\n    add_generation_prompt = True, # Must add for generation\n    return_tensors = \"pt\",\n).to(\"cuda\")\n\nfrom transformers import TextStreamer\ntext_streamer = TextStreamer(tokenizer, skip_prompt = True)\n_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n                   use_cache = True, temperature = 1.5, min_p = 0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-21T14:16:18.927650Z","iopub.execute_input":"2024-11-21T14:16:18.928540Z","iopub.status.idle":"2024-11-21T14:16:27.222717Z","shell.execute_reply.started":"2024-11-21T14:16:18.928501Z","shell.execute_reply":"2024-11-21T14:16:27.222003Z"}},"outputs":[{"name":"stderr","text":"The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","output_type":"stream"},{"name":"stdout","text":"Agriculture is the practice of cultivating the land and producing crops and livestock to feed a population. It involves the management of agricultural resources, such as land, water, soil, and living organisms, to produce food, fiber, and other agricultural products. Agriculture is a vital component of the global economy, providing a significant portion of the world's food, and its significance cannot be overstated.\n\nThere are several key aspects of agriculture:\n\n1. **Crop production**: Planting, growing, and harvesting crops such as grains, fruits, and vegetables.\n2. **Livestock production**: Raising animals, such as cattle, pigs,\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}